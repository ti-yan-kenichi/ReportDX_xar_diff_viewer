
import io
import zipfile
import json
import difflib
from typing import Any, Dict, List, Tuple

import streamlit as st
import pandas as pd

st.set_page_config(page_title="å¸³ç¥¨DX ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå·®åˆ†ãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆMD & Excelãƒ¬ãƒãƒ¼ãƒˆç‰ˆï¼‰", layout="wide")

st.title("ğŸ“„ å¸³ç¥¨DX ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå·®åˆ†ãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆMD & Excelãƒ¬ãƒãƒ¼ãƒˆç‰ˆï¼‰")
st.write(
    "ã‚ªãƒ—ãƒ­ã®å¸³ç¥¨DXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ.xarï¼‰ãƒ•ã‚¡ã‚¤ãƒ«åŒå£«ã®å·®åˆ†ã‚’ã€ã§ãã‚‹ã ã‘è©³ç´°ã«æ¯”è¼ƒã—ã€Markdownãƒ¬ãƒãƒ¼ãƒˆã¨Excelãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚"
)

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ UI -------------------------------------------------

col1, col2 = st.columns(2)
with col1:
    old_file = st.file_uploader("æ—§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ (.xar)", type=["xar"], key="old")
with col2:
    new_file = st.file_uploader("æ–°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ (.xar)", type=["xar"], key="new")


# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----------------------------------------------------------


def load_xar_from_bytes(bytes_data: bytes) -> Tuple[Dict[str, Any], str]:
    # Uploadã•ã‚ŒãŸ .xar (ZIP) ã‹ã‚‰ .xat JSON ã¨å…ƒãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
    with zipfile.ZipFile(io.BytesIO(bytes_data)) as z:
        xat_name = None
        for name in z.namelist():
            if name.lower().endswith(".xat"):
                xat_name = name
                break
        if not xat_name:
            raise ValueError(".xar å†…ã« .xat ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        data = z.read(xat_name)
        txt = data.decode("utf-8")
        return json.loads(txt), txt


def index_objects(tpl_json: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    # objectsé…åˆ—ã‚’idã§å¼•ã‘ã‚‹dictã«å¤‰æ›
    return {
        o.get("id"): o
        for o in tpl_json.get("objects", [])
        if o.get("id") is not None
    }


def summarize_object(o: Dict[str, Any]) -> Dict[str, Any]:
    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ¦‚ç•¥ã‚’å–ã‚Šå‡ºã™ï¼ˆä¸€è¦§è¡¨ç¤ºç”¨ï¼‰
    impl_uri = o.get("impl_uri")
    rect = o.get("rect", {}) or {}
    base = {
        "id": o.get("id"),
        "name": o.get("name"),
        "type": impl_uri,
        "x": rect.get("x"),
        "y": rect.get("y"),
        "width": rect.get("width"),
        "height": rect.get("height"),
        "show": o.get("show"),
        "lock": o.get("lock"),
        "enabled": o.get("enabled"),
    }

    impl = o.get("impl", {}) or {}

    if impl_uri == "oxa:text":
        data = impl.get("data", {}) or {}
        font = impl.get("font", {}) or {}
        base.update(
            {
                "kind": "text",
                "text": data.get("value"),
                "font_name": font.get("name"),
                "font_size": font.get("size"),
                "font_color": font.get("color"),
                "align": font.get("align"),
            }
        )
    elif impl_uri == "oxa:rect":
        stroke = impl.get("stroke", {}) or {}
        fill = stroke.get("fill", {}) or {}
        base.update(
            {
                "kind": "rect",
                "stroke_size": stroke.get("size"),
                "stroke_color": fill.get("color"),
            }
        )
    elif impl_uri == "oxa:tableregion":
        tables = impl.get("tables", []) or []
        table = tables[0] if tables else {}
        drive_ds = table.get("drive_dataset", {}) or {}
        details = table.get("details", []) or []
        col_count = 0
        if details:
            first_detail = details[0]
            frames = first_detail.get("frames", []) or []
            col_count = len(frames)
        base.update(
            {
                "kind": "tableregion",
                "dataset_ref": drive_ds.get("ref"),
                "column_count": col_count,
            }
        )
    else:
        base.update({"kind": "other"})

    return base


def deep_diff(a: Any, b: Any, path: str = "") -> List[Dict[str, Any]]:
    # JSONã®ä¸€éƒ¨ï¼ˆdict/list/å€¤ï¼‰åŒå£«ã‚’æ¯”è¼ƒã—ã¦ã€å·®åˆ†ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    # å„è¦ç´ ã¯ {path, old, new} ã‚’æŒã¤ã€‚
    diffs: List[Dict[str, Any]] = []

    # å‹ãŒé•ã†å ´åˆã¯å³å·®åˆ†
    if type(a) is not type(b):
        if a != b:
            diffs.append({"path": path or "(root)", "old": a, "new": b})
        return diffs

    # dict
    if isinstance(a, dict):
        keys = set(a.keys()) | set(b.keys())
        for k in sorted(keys):
            sub_path = f"{path}.{k}" if path else k
            if k not in a:
                diffs.append({"path": sub_path, "old": None, "new": b.get(k)})
            elif k not in b:
                diffs.append({"path": sub_path, "old": a.get(k), "new": None})
            else:
                diffs.extend(deep_diff(a.get(k), b.get(k), sub_path))
        return diffs

    # list
    if isinstance(a, list):
        max_len = max(len(a), len(b))
        for i in range(max_len):
            sub_path = f"{path}[{i}]"
            if i >= len(a):
                diffs.append({"path": sub_path, "old": None, "new": b[i]})
            elif i >= len(b):
                diffs.append({"path": sub_path, "old": a[i], "new": None})
            else:
                diffs.extend(deep_diff(a[i], b[i], sub_path))
        return diffs

    # å€¤
    if a != b:
        diffs.append({"path": path or "(root)", "old": a, "new": b})
    return diffs


def classify_severity(path: str) -> Tuple[int, str, str]:
    # å·®åˆ†ãƒ‘ã‚¹ã«åŸºã¥ã„ã¦é‡è¦åº¦ã‚’åˆ¤å®šã™ã‚‹ã€‚
    # æˆ»ã‚Šå€¤: (severity, emoji, label)  / severity: 3=Critical, 2=Medium, 1=Minor
    p = path.lower()

    # é‡å¤§ï¼šãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒ‰ã‚„ã‚¿ã‚¤ãƒ—ã€åˆ—æ•°ãªã©
    critical_keywords = [
        "drive_dataset",
        "dataset_ref",
        "dataset",
        "bind",
        "impl_uri",
        "column_count",
        ".tables",
        "image",
        "img",
        "resource",
    ]
    if any(k in p for k in critical_keywords):
        return 3, "ğŸ”´", "é‡å¤§"

    # ä¸­ç¨‹åº¦ï¼šãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºãªã©
    medium_keywords = [
        "rect.",
        ".rect",
        "stroke",
        "font_size",
        "font.size",
        "fill.color",
        "fill_colour",
        "alignment",
        "align",
        "width",
        "height",
        "x",
        "y",
        "rotation",
        "skew",
    ]
    if any(k in p for k in medium_keywords):
        return 2, "ğŸŸ¡", "ä¸­"

    # ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›´ã¯ä¸­ã€œé‡å¤§ã¨ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ãŒã€ã“ã“ã§ã¯ä¸­ã«å¯„ã›ã‚‹
    if "impl.data.value" in p or "text" in p:
        return 2, "ğŸŸ¡", "ä¸­"

    # ãã‚Œä»¥å¤–ã¯è»½å¾®
    return 1, "ğŸŸ¢", "è»½å¾®"


def html_colored_change(path: str, old: Any, new: Any) -> str:
    # å·®åˆ†1ä»¶ã‚’HTMLï¼ˆè‰²ä»˜ãï¼‰ã§è¡¨ç¾ã™ã‚‹
    severity, emoji, label = classify_severity(path)
    if severity == 3:
        color = "red"
    elif severity == 2:
        color = "orange"
    else:
        color = "green"

    old_str = json.dumps(old, ensure_ascii=False)
    new_str = json.dumps(new, ensure_ascii=False)

    return (
        f'<div style="margin-bottom:4px;">'
        f'<span style="color:{color}; font-weight:bold;">{emoji} [{label}]</span> '
        f'<code>{path}</code><br>'
        f'<span style="color:{color};">æ—§: {old_str}</span><br>'
        f'<span style="color:{color};">æ–°: {new_str}</span>'
        f"</div>"
    )


def build_markdown_report(
    old_name: str,
    new_name: str,
    added: List[Dict[str, Any]],
    removed: List[Dict[str, Any]],
    changed_rows: List[Dict[str, Any]],
    changed_detail: Dict[str, Any],
) -> str:
    # Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹
    lines: List[str] = []
    lines.append("# å¸³ç¥¨DX ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå·®åˆ†ãƒ¬ãƒãƒ¼ãƒˆ")
    lines.append("")
    lines.append(f"- æ—§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: `{old_name}`")
    lines.append(f"- æ–°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: `{new_name}`")
    lines.append("")

    total_critical = sum(r["critical_cnt"] for r in changed_rows)
    total_medium = sum(r["medium_cnt"] for r in changed_rows)
    total_minor = sum(r["minor_cnt"] for r in changed_rows)

    lines.append("## ã‚µãƒãƒªãƒ¼")
    lines.append("")
    lines.append(f"- è¿½åŠ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: **{len(added)}**")
    lines.append(f"- å‰Šé™¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: **{len(removed)}**")
    lines.append(f"- å¤‰æ›´ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: **{len(changed_rows)}**")
    lines.append(f"- é‡å¤§å¤‰æ›´(ğŸ”´): **{total_critical}**")
    lines.append(f"- ä¸­å¤‰æ›´(ğŸŸ¡): **{total_medium}**")
    lines.append(f"- è»½å¾®å¤‰æ›´(ğŸŸ¢): **{total_minor}**")
    lines.append("")

    lines.append("## è¿½åŠ ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ")
    lines.append("")
    if not added:
        lines.append("- ãªã—")
    else:
        lines.append("| id | name | kind | type | x | y | width | height |")
        lines.append("| --- | --- | --- | --- | --- | --- | --- | --- |")
        for o in added:
            lines.append(
                f"| `{o.get('id')}` | {o.get('name','')} | {o.get('kind','')} | "
                f"{o.get('type','')} | {o.get('x','')} | {o.get('y','')} | "
                f"{o.get('width','')} | {o.get('height','')} |"
            )
    lines.append("")

    lines.append("## å‰Šé™¤ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ")
    lines.append("")
    if not removed:
        lines.append("- ãªã—")
    else:
        lines.append("| id | name | kind | type | x | y | width | height |")
        lines.append("| --- | --- | --- | --- | --- | --- | --- | --- |")
        for o in removed:
            lines.append(
                f"| `{o.get('id')}` | {o.get('name','')} | {o.get('kind','')} | "
                f"{o.get('type','')} | {o.get('x','')} | {o.get('y','')} | "
                f"{o.get('width','')} | {o.get('height','')} |"
            )
    lines.append("")

    lines.append("## å¤‰æ›´ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè©³ç´°")
    lines.append("")
    if not changed_rows:
        lines.append("- ãªã—")
    else:
        for row in changed_rows:
            oid = row["id"]
            det = changed_detail[oid]
            lines.append(f"### ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ `{oid}`")
            lines.append("")
            lines.append(
                f"- kind/type: `{row.get('kind')}` / `{row.get('type')}`"
            )
            lines.append(
                f"- name: `{row.get('name_old')}` â†’ `{row.get('name_new')}`"
            )
            lines.append(
                f"- å¤‰æ›´ä»¶æ•°: é‡å¤§={row.get('critical_cnt')} / ä¸­={row.get('medium_cnt')} / è»½å¾®={row.get('minor_cnt')}"
            )
            lines.append("")
            lines.append("#### å·®åˆ†ä¸€è¦§")
            lines.append("")

            diffs = det["diffs"]
            decorated: List[Tuple[int, str, str, Any, Any]] = []
            for d in diffs:
                severity, emoji, label = classify_severity(d["path"])
                decorated.append(
                    (severity, emoji, label, d["path"], d["old"], d["new"])
                )
            decorated.sort(key=lambda x: (-x[0], x[3]))

            lines.append("| é‡è¦åº¦ | ãƒ‘ã‚¹ | æ—§å€¤ | æ–°å€¤ |")
            lines.append("| --- | --- | --- | --- |")
            for severity, emoji, label, path, old, new in decorated:
                old_str = json.dumps(old, ensure_ascii=False)
                new_str = json.dumps(new, ensure_ascii=False)
                lines.append(
                    f"| {emoji} {label} | `{path}` | `{old_str}` | `{new_str}` |"
                )
            lines.append("")

    return "\n".join(lines)


def build_excel_report(
    added: List[Dict[str, Any]],
    removed: List[Dict[str, Any]],
    changed_rows: List[Dict[str, Any]],
    changed_detail: Dict[str, Any],
) -> bytes:
    # Excelãƒ¬ãƒãƒ¼ãƒˆï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆï¼‰ã‚’ç”Ÿæˆ
    with io.BytesIO() as buffer:
        with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
            # Added / Removed / Changed summary
            if added:
                df_added = pd.DataFrame(added)
                df_added.to_excel(writer, sheet_name="Added", index=False)
            else:
                pd.DataFrame(columns=["id", "name"]).to_excel(
                    writer, sheet_name="Added", index=False
                )

            if removed:
                df_removed = pd.DataFrame(removed)
                df_removed.to_excel(writer, sheet_name="Removed", index=False)
            else:
                pd.DataFrame(columns=["id", "name"]).to_excel(
                    writer, sheet_name="Removed", index=False
                )

            if changed_rows:
                df_changed = pd.DataFrame(changed_rows)
                df_changed.to_excel(writer, sheet_name="ChangedSummary", index=False)
            else:
                pd.DataFrame(columns=["id", "name"]).to_excel(
                    writer, sheet_name="ChangedSummary", index=False
                )

            # Changed details (flattened)
            detail_rows: List[Dict[str, Any]] = []
            for row in changed_rows:
                oid = row["id"]
                det = changed_detail[oid]
                diffs = det["diffs"]
                for d in diffs:
                    sev, emoji, label = classify_severity(d["path"])
                    detail_rows.append(
                        {
                            "id": oid,
                            "name_old": row.get("name_old"),
                            "name_new": row.get("name_new"),
                            "kind": row.get("kind"),
                            "type": row.get("type"),
                            "severity": sev,
                            "level": label,
                            "emoji": emoji,
                            "path": d["path"],
                            "old": json.dumps(d["old"], ensure_ascii=False),
                            "new": json.dumps(d["new"], ensure_ascii=False),
                        }
                    )

            if detail_rows:
                df_detail = pd.DataFrame(detail_rows)
            else:
                df_detail = pd.DataFrame(
                    columns=[
                        "id",
                        "name_old",
                        "name_new",
                        "kind",
                        "type",
                        "severity",
                        "level",
                        "emoji",
                        "path",
                        "old",
                        "new",
                    ]
                )
            df_detail.to_excel(writer, sheet_name="ChangedDetails", index=False)

        return buffer.getvalue()


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† --------------------------------------------------------------

if old_file is not None and new_file is not None:
    try:
        old_bytes = old_file.read()
        new_bytes = new_file.read()
        tpl_old, txt_old = load_xar_from_bytes(old_bytes)
        tpl_new, txt_new = load_xar_from_bytes(new_bytes)
    except Exception as e:
        st.error(f".xar ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    else:
        idx_old = index_objects(tpl_old)
        idx_new = index_objects(tpl_new)

        ids_old = set(idx_old.keys())
        ids_new = set(idx_new.keys())

        added_ids = ids_new - ids_old
        removed_ids = ids_old - ids_new
        common_ids = ids_old & ids_new

        # ã‚µãƒãƒªãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        added = [summarize_object(idx_new[i]) for i in sorted(added_ids)]
        removed = [summarize_object(idx_old[i]) for i in sorted(removed_ids)]

        changed_rows: List[Dict[str, Any]] = []
        changed_detail: Dict[str, Any] = {}

        for oid in sorted(common_ids):
            o_old = idx_old[oid]
            o_new = idx_new[oid]
            sa = summarize_object(o_old)
            sb = summarize_object(o_new)

            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®deep diffï¼ˆrect/implãªã©ã™ã¹ã¦å«ã‚€ï¼‰
            obj_diffs = deep_diff(o_old, o_new, path="object")

            if obj_diffs:
                # é‡è¦åº¦ã”ã¨ã«ã‚«ã‚¦ãƒ³ãƒˆ
                sev_counts = {1: 0, 2: 0, 3: 0}
                for d in obj_diffs:
                    severity, _emoji, _label = classify_severity(d["path"])
                    sev_counts[severity] += 1

                changed_rows.append(
                    {
                        "id": oid,
                        "name_old": sa.get("name"),
                        "name_new": sb.get("name"),
                        "kind": sa.get("kind"),
                        "type": sa.get("type"),
                        "minor_cnt": sev_counts[1],
                        "medium_cnt": sev_counts[2],
                        "critical_cnt": sev_counts[3],
                        "total_changes": sum(sev_counts.values()),
                    }
                )
                changed_detail[oid] = {
                    "old_summary": sa,
                    "new_summary": sb,
                    "old_full": o_old,
                    "new_full": o_new,
                    "diffs": obj_diffs,
                }

        st.subheader("å·®åˆ†ã‚µãƒãƒªãƒ¼")

        total_critical = sum(r["critical_cnt"] for r in changed_rows)
        total_medium = sum(r["medium_cnt"] for r in changed_rows)
        total_minor = sum(r["minor_cnt"] for r in changed_rows)

        c1, c2, c3, c4, c5 = st.columns(5)
        c1.metric("è¿½åŠ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ", len(added_ids))
        c2.metric("å‰Šé™¤ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ", len(removed_ids))
        c3.metric("å¤‰æ›´ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ", len(changed_rows))
        c4.metric("é‡å¤§å¤‰æ›´(ğŸ”´)", total_critical)
        c5.metric("ä¸­å¤‰æ›´(ğŸŸ¡) / è»½å¾®(ğŸŸ¢)", f"{total_medium} / {total_minor}")

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        st.markdown("### ğŸ“¥ å·®åˆ†ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

        md_report = build_markdown_report(
            old_name=getattr(old_file, "name", "old.xar"),
            new_name=getattr(new_file, "name", "new.xar"),
            added=added,
            removed=removed,
            changed_rows=changed_rows,
            changed_detail=changed_detail,
        )

        st.download_button(
            label="Markdownãƒ¬ãƒãƒ¼ãƒˆï¼ˆ.mdï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=md_report.encode("utf-8"),
            file_name="xar_diff_report.md",
            mime="text/markdown",
        )

        excel_bytes = build_excel_report(
            added=added,
            removed=removed,
            changed_rows=changed_rows,
            changed_detail=changed_detail,
        )

        st.download_button(
            label="Excelãƒ¬ãƒãƒ¼ãƒˆï¼ˆ.xlsxï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=excel_bytes,
            file_name="xar_diff_report.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.markdown("---")

        # è¿½åŠ ãƒ»å‰Šé™¤ãƒ»å¤‰æ›´ã”ã¨ã®ã‚¿ãƒ– + JSON diffã‚¿ãƒ–
        tab1, tab2, tab3, tab4 = st.tabs(
            ["â• è¿½åŠ ", "â– å‰Šé™¤", "âœï¸ å¤‰æ›´ï¼ˆè‰²åˆ†ã‘ä»˜ãï¼‰", "ğŸ§¾ JSONãƒ†ã‚­ã‚¹ãƒˆå·®åˆ†"]
        )

        with tab1:
            st.markdown("### è¿½åŠ ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ")
            if not added:
                st.info("è¿½åŠ ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.dataframe(added, use_container_width=True)

        with tab2:
            st.markdown("### å‰Šé™¤ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ")
            if not removed:
                st.info("å‰Šé™¤ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.dataframe(removed, use_container_width=True)

        with tab3:
            st.markdown("### å¤‰æ›´ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§")
            if not changed_rows:
                st.info("å¤‰æ›´ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.dataframe(changed_rows, use_container_width=True)

                st.markdown("#### ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆ¥ã®è©³ç´°å·®åˆ†")

                selected_id = st.selectbox(
                    "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆIDã‚’é¸æŠ", [row["id"] for row in changed_rows]
                )
                detail = changed_detail[selected_id]

                st.write(f"**ID:** `{selected_id}`")
                st.write(
                    f"**æ—§name:** {detail['old_summary'].get('name')} / "
                    f"**æ–°name:** {detail['new_summary'].get('name')}"
                )
                st.write(
                    f"**kind/type:** {detail['old_summary'].get('kind')} / "
                    f"{detail['old_summary'].get('type')}"
                )

                # é‡è¦åº¦ã”ã¨ã«ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤ºï¼ˆé‡å¤§ â†’ ä¸­ â†’ è»½å¾®ï¼‰
                diffs = detail["diffs"]
                diffs_with_sev = []
                for d in diffs:
                    severity, emoji, label = classify_severity(d["path"])
                    diffs_with_sev.append(
                        {
                            "severity": severity,
                            "emoji": emoji,
                            "label": label,
                            "path": d["path"],
                            "old": d["old"],
                            "new": d["new"],
                        }
                    )

                diffs_with_sev.sort(
                    key=lambda x: (-x["severity"], x["path"])
                )  # é‡å¤§ã‹ã‚‰

                st.markdown("##### å·®åˆ†ä¸€è¦§ï¼ˆè‰²åˆ†ã‘ï¼‰")

                if not diffs_with_sev:
                    st.write("ã“ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¯å·®åˆ†ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    html_blocks = [
                        html_colored_change(
                            d["path"],
                            d["old"],
                            d["new"],
                        )
                        for d in diffs_with_sev
                    ]
                    st.markdown(
                        "\n".join(html_blocks),
                        unsafe_allow_html=True,
                    )

                with st.expander("æ—§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆJSONï¼‰"):
                    st.json(detail["old_full"])
                with st.expander("æ–°ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆJSONï¼‰"):
                    st.json(detail["new_full"])

        with tab4:
            st.markdown("### JSON ãƒ†ã‚­ã‚¹ãƒˆã®å®Œå…¨ diff")
            diff_lines = difflib.unified_diff(
                txt_old.splitlines(),
                txt_new.splitlines(),
                fromfile="old.xat",
                tofile="new.xat",
                lineterm="",
            )
            diff_text = "\n".join(diff_lines)
            st.code(diff_text or "å·®åˆ†ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", language="diff")

else:
    st.info("å·¦ã«æ—§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€å³ã«æ–°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã® .xar ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
